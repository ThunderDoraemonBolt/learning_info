\documentclass[twoside]{article}

\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{siunitx}
\usepackage{layout}
\usepackage{titlesec}
\usepackage{etoolbox}
\usepackage{cancel}
\usepackage{xcolor}


\usepackage{geometry}
\usepackage[skip=\bigskipamount, indent]{parskip} % bigskip between paragraphs
\usepackage{lipsum}
\usepackage[most]{tcolorbox}
\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{calc}
\usepackage{hyperref}
\usepackage{fourier-orns}
\usepackage{fontawesome5}
\usepackage{fancyhdr}


\geometry{top = 1.0in, bottom = 1.0in, left = 0.9in, right = 0.9in} % Set page margins

\definecolor{RoyalBlue}{HTML}{16348C} % Section title colour
\definecolor{DeepPurple}{HTML}{440150} % Subsection title colour
\definecolor{DeepGreen}{HTML}{0B6623} % Subsubsection title colour
\definecolor{DeepLavendar}{HTML}{7373E3} % Question box boundary colour
\definecolor{Lavendar}{HTML}{E6E6FA} % Question box colour
\definecolor{DeepTeaGreen}{HTML}{62C92F} % Answer box boundary colour
\definecolor{TeaGreen}{HTML}{D1F5BF} % Answer box colour
\definecolor{DeepBubbleGumBlue}{HTML}{57CEEE} % Remarks box boundary colour
\definecolor{BubbleGumBlue}{HTML}{CDF9FA} % Remarks box colour
\definecolor{Cream}{HTML}{FDFCC3} % Derivation box colour
\definecolor{DeepCream}{HTML}{FBF65E} % Derivation box boundary colour
\definecolor{Almond}{HTML}{F4E7DB} % Example box colour
\definecolor{DeepAlmond}{HTML}{E0BE9C} % Example box boundary colour
\definecolor{MidnightBlue}{HTML}{191970} % Hyperlink colour
\definecolor{CobaltBlue}{HTML}{0047AB} % Reference colour



\newlength\titleindent
\setlength\titleindent{3em} % Title indentations
\setlength\parindent{0pt} % No indent for all paragraphs

\titleformat{\section}{\normalfont\Large\bfseries\color{RoyalBlue}}{\llap{\parbox{\titleindent}{\thesection\hfill}}}{0em}{}
\titleformat{\subsection}{\normalfont\normalsize\bfseries\color{DeepPurple}}{\llap{\parbox{\titleindent}{\thesubsection\hfill}}}{0em}{}
\titleformat{\subsubsection}{\normalfont\normalsize\bfseries\color{DeepGreen}}{\llap{\parbox{\titleindent}{\thesubsubsection\hfill}}}{0em}{}

\pgfplotsset{compat = 1.18}

\hypersetup{
	colorlinks = true,
	urlcolor = MidnightBlue,
	linkcolor = CobaltBlue,
}

% Define the volume symbol
\makeatletter
\DeclareRobustCommand{\vol}{\text{\volumedash}V}
\newcommand{\volumedash}{%
	\makebox[0pt][l]{%
		\ooalign{\hfil\hphantom{$\m@th V$}\hfil\cr\kern0.16em\rotatebox{27.5}{\textbf{--}}\hfil\cr}%
	}%
}
\makeatother


% Define definition box
\newtcolorbox{definitionbox}{enhanced, parbox = false, boxrule = 0mm, boxsep = 0mm,
							 arc = 0mm, outer arc = 0mm,
							 left = 4mm, right = 3mm, top = 7pt, bottom = 7pt,
							 toptitle = 1mm, bottomtitle = 1mm, oversize,
							 borderline west = {5pt}{0pt}{DeepLavendar}, colback = Lavendar}
\newcommand{\definition}[1]{\begin{definitionbox} \textcolor{red}{{\scriptsize\faStar} \textbf{Definition}} \newline \rule{\textwidth}{0.5pt}  \newline #1 \end{definitionbox}}

% Define answer box
\newtcolorbox{answerbox}{enhanced, parbox = false, boxrule = 0mm, boxsep = 0mm,
	arc = 0mm, outer arc = 0mm,
	left = 4mm, right = 3mm, top = 7pt, bottom = 7pt,
	toptitle = 1mm, bottomtitle = 1mm, oversize,
	borderline west = {5pt}{0pt}{DeepTeaGreen}, colback = TeaGreen}
\newcommand{\answer}[1]{\begin{answerbox} \textbf{Answer} \newline #1 \end{answerbox}}

% Define remarks box
\newtcolorbox{remarksbox}{enhanced, parbox = false, boxrule = 0mm, boxsep = 0mm,
	arc = 0mm, outer arc = 0mm,
	left = 4mm, right = 3mm, top = 7pt, bottom = 7pt,
	toptitle = 1mm, bottomtitle = 1mm, oversize,
	borderline west = {5pt}{0pt}{DeepBubbleGumBlue}, colback = BubbleGumBlue}
\newcommand{\remarks}[1]{\begin{remarksbox} \textbf{Remarks} \newline #1 \end{remarksbox}}

% Define derivation box
\newtcolorbox{derivationbox}{enhanced, parbox = false, boxrule = 0mm, boxsep = 0mm,
	arc = 0mm, outer arc = 0mm,
	left = 4mm, right = 3mm, top = 7pt, bottom = 7pt,
	toptitle = 1mm, bottomtitle = 1mm, oversize,
	borderline west = {5pt}{0pt}{DeepCream}, colback = Cream}
\newcommand{\derivation}[1]{\begin{derivationbox} \textbf{Equation Derivation} \newline #1 \end{derivationbox}}

% Define derivation box
\newtcolorbox{examplebox}{enhanced, parbox = false, boxrule = 0mm, boxsep = 0mm,
	arc = 0mm, outer arc = 0mm,
	left = 4mm, right = 3mm, top = 7pt, bottom = 7pt,
	toptitle = 1mm, bottomtitle = 1mm, oversize,
	borderline west = {5pt}{0pt}{DeepAlmond}, colback = Almond}
\newcommand{\example}[1]{\begin{examplebox} \textbf{Example} \newline #1 \end{examplebox}}

% Define blue text
\newcommand{\highlightbluetext}[1]{\textcolor[HTML]{09ACA6}{\textbf{#1}}}

% Define green text
\newcommand{\highlightgreentext}[1]{\textcolor[HTML]{62C92F}{\textbf{#1}}}

% Numbers with circle
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{\node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\numberwithin{equation}{section}

\usetikzlibrary{arrows.meta, positioning}

\begin{document}
	\begin{titlepage}
		\centering
		\scshape
		\vspace*{\baselineskip}
		
		\rule{\textwidth}{1.6pt}\vspace{-\baselineskip}\vspace{2pt} % Thick horizontal rule
		\rule{\textwidth}{0.4pt} % Thin horizontal rule
		
		\vspace{0.5\baselineskip}
		
		{\LARGE \textbf{COMP4211 \\ Machine Learning} \\
			
			\vspace{0.75\baselineskip}
			\Large Notes}
		
		\vspace{0.5\baselineskip}
		
		\rule{\textwidth}{0.4pt}\vspace{-\baselineskip}\vspace{3.2pt} % Thin horizontal rule
		\rule{\textwidth}{1.6pt} % Thick horizontal rule
		
		\vspace{1.5\baselineskip}
		
		{\large Insturctor: Dit Yan, Yeung \\
			\vspace{0.5\baselineskip} Fall 2025}
		
		\vspace{\baselineskip}
		
		{\Large Edited by \\
			\vspace{0.5\baselineskip}
			\Large ThunderDora \\

			\vspace{10pt}
			\large \textit{The Hong Kong University of Science and Technology}}
		
		\vspace{10\baselineskip}
		
		\textit{Last Edited: \textbf{\today}}
		
	\end{titlepage}
	
	\newpage
	
	% Configure the headers and footers
	\pagestyle{fancy}
	\fancyhf{}
	\renewcommand{\headrulewidth}{0pt}
	\fancyhead[C]{\large \textbf{COMP4211 - Machine Learning}}
	
	\fancyfoot{}

	\fancyfoot[RO, LE]{\thepage}
	
	\setcounter{page}{1}
	
	\tableofcontents
	
	\newpage
	
	\section{Machine Learning}
	\label{sec:MachineLearning}
	
	\subsection{What is Machine Learning?}
	\label{subsec:WhatIsMachineLearning}

	\definition{Machine Learning is the science of \highlightgreentext{making computer artifacts improve their performance} with respect to a certain performance criterion using example data without requring humans to explicitly program the rules for improvement.}
	
	Machine Learning problems can be categorized into three main types:
	\begin{itemize}
		\item \highlightbluetext{Supervised Learning}: Algorithm that learns from a labeled dataset, where the input data corresponds to the accurate output.
		\item \highlightbluetext{Unsupervised Learning}: Model that is developed using an unlabeled dataset, in which the input data lacks associated output labels.
		\item \highlightbluetext{Reinforcement Learning}: Algorithm that acquires knowledge through engagement with an environment, obtaining feedback as rewards or penalties depending on its actions.
	\end{itemize}

	\subsection{What is Supervised Learning?}
	\label{subsec:WhatIsSupervisedLearning}
	The fundamental steps of supervised learning is outlined below:
	\begin{enumerate}
		\item Consider a training set $S = \{(\mathbf{x}^{(l)}, \mathbf{y}^{(l)})\}_{l=1}^N$ consisting of $N$ labeled pairs of inputs and outputs. 
		\item Identify a function $f(\cdot)$ with the training set $S$ so that $f(\mathbf{x}^{(l)}) \approx \mathbf{y}^{(l)}$ holds for all $l = 1, \ldots, N$, and that $f(\mathbf{x})$ for new examples $\mathbf{x}$ also results in $f(\mathbf{x}) \approx \mathbf{y}$ from the same distribution. 
		\item In the testing stage, examples without labels containing only the input $\mathbf{x}$ are given, and the model determines the output $\mathbf{y}$ by applying the learned function $f(\mathbf{x})$.
	\end{enumerate}

	Supervised learning is generally applied to address two kinds of issues: 
	\begin{itemize} 
		\item \highlightbluetext{Classification}: The output $\mathbf{y}$ is a \highlightgreentext{categorical} value, like a label class. 
		\item \highlightbluetext{Regression}: The output $\mathbf{y}$ is a \highlightgreentext{continuous} quantity, like a real number. 
	\end{itemize}

	\subsection{What is Unsupervised Learning?}
	\label{subsec:WhatIsUnsupervisedLearning}

	The basic steps of unsupervised learning are detailed below:
	\begin{enumerate}
		\item Take a training set $S = \{\mathbf{x}^{(l)}\}_{l=1}^N$ that contains $N$ inputs without labels.
		\item Determine a function $f(\cdot)$ using the training set $S$ such that $f(\mathbf{x}^{(l)})$ represents the essential pattern of the data
	\end{enumerate}

	Unsupervised learning is typically utilized to tackle four types of problems:
	\begin{itemize}
		\item \highlightbluetext{Clustering}: Method that organizes the data into clusters by their similarities. 
		\item \highlightbluetext{Dimensionality Reduction}: Algorithm that minimizes the number of attributes while maintaining crucial information. 
		\item \highlightbluetext{Anomaly Detection}: Algorithm that detects atypical patterns that deviate from anticipated behavior. 
		\item \highlightbluetext{Density Estimation}: Method that calculates the likelihood distribution of the data. 
	\end{itemize}

	\newpage
	\subsection{What is Reinforcement Learning?}
	\label{subsec:WhatIsReinforcementLearning}
	Reinforcement learning is a form of machine learning in which an agent learns to make choices by performing actions in an environment to optimize total rewards. The essential elements of reinforcement learning are: 
	\begin{itemize}
		\item \highlightbluetext{Agent}: Entity making decisions or learning by engaging with the environment. 
		\item \highlightbluetext{Environment}: Outside system that the agent engages with. 
		\item \highlightbluetext{State}: Depiction of the existing circumstances of the environment. 
		\item \highlightbluetext{Action}: Decision made by the agent that influences the condition of the environment. 
		\item \highlightbluetext{Reward}: Feedback signal obtained by the agent following an action, showing how effective or ineffective that action was. 
	\end{itemize} 
	The reinforcement learning process entails the agent noticing the existing state of the environment, choosing an action guided by a policy, obtaining a reward, and refining its policy to enhance future actions.

	\begin{center}
		\begin{tikzpicture}[
			box/.style={draw, thick, rectangle, minimum width=2cm, minimum height=1.5cm},
			arrow/.style={thick, -Stealth}
		]

		% Draw the boxes
		\node[box] (agent) {Agent};
		\node[box, right=4cm of agent] (environment) {Environment};

		% Draw the arrows
		\draw[arrow] (agent.east) -- node[above] {Action} (environment.west);
		\draw[arrow] (environment.south) -- ++(0,-0.5) -| node[pos=0.25, below] {State \& Reward} (agent.south);

		\end{tikzpicture}
	\end{center}

	\newpage
	\section{Linear Regression}
	\label{sec:LinearRegression}

	\subsection{What is Regression?}
	\label{subsec:WhatIsRegression}

	\definition{Regression is a statistical modeling approach used to estimate the \highlightgreentext{relationship between a dependent variable and one or several independent variables that may contain errors}. The aim of regression is to identify the most suitable line or curve that represents the connection between the variables.}

	The fundamental concept of regression can be illustrated through the following steps: 
	\begin{enumerate}
		\item Consider a training set $S = \{(\mathbf{x}^{(l)}, \mathbf{y}^{(l)})\}_{l=1}^N$ which comprises $N$ pairs of inputs and corresponding outputs, with $\mathbf{x}^{(l)}$ representing the input and $\mathbf{y}^{(l)}$ denoting the output. 
		\item The input $\mathbf{x} = (x_1, x_2, \ldots, x_d)$ represents a vector in $d$ dimensions, with $d$ denoting the count of features or attributes. 
		\item \highlightbluetext{Regression Function $f(\cdot ; \mathbf{w})$} employs $S$ to ensure the predicted outcome $f(\mathbf{x}^{(l)} ; \mathbf{w})$ is as near as feasible to the true output $\mathbf{y}^{(l)}$ for every $l = 1, \ldots, N$, with $\mathbf{w}$ representing the parameter vector of the regression function. 
		\item When the output $\mathbf{y}$ consists of a multivariate vector, it represents a \highlightgreentext{multi-output regression} issue. For a univariate result, it constitutes a \highlightgreentext{single-output regression} issue. 
	\end{enumerate}

	\subsection{Linear Regression Function}
	\label{subsec:LinearRegressionFunction}
	If the regression function $f(\mathbf{x} ; \mathbf{w})$ is \highlightbluetext{linear}, it can be expressed as:
	\begin{equation}
	\label{eq:LinearRegressionFunction}
	\boxed{f(\mathbf{x} ; \mathbf{w}) = w_0 + w_1 x_1 + w_2 x_2 + \ldots + w_d x_d = \begin{bmatrix} w_0 & w_1 & w_2 & \ldots & w_d \end{bmatrix} \begin{bmatrix} 1 \\ x_1 \\ x_2 \\ \vdots \\ x_d \end{bmatrix} = \mathbf{w}^T \mathbf{\tilde{x}} = \mathbf{\tilde{x}}^T \mathbf{w}}
	\end{equation}
	
	\begin{itemize}
		\item Weight $w_0$ represents the \highlightbluetext{bias} term, which is a fixed value that acts as an adjustment for the regression function. 
		\item Learning problem involves identifying the optimal parameter vector $\mathbf{w} = (w_0, w_1, \ldots, w_d)$ that reduces the discrepancy between the predicted output $f(\mathbf{x}^{(l)} ; \mathbf{w})$ and the actual output $\mathbf{y}^{(l)}$ for every $l = 1, \ldots, N$.
	\end{itemize}

	\subsection{Squared Loss Function}
	\label{subsec:SquaredLossFunction}
	To determine the parameter vector $\mathbf{w}$ of the linear regression function $f(\mathbf{x}; \mathbf{w})$, it is essential to establish a loss function $L(\mathbf{w}; S)$ that measures the discrepancy between the predicted output and the true output. The loss function most frequently utilized for linear regression is the \highlightbluetext{squared loss function}, defined as:
	\begin{equation}
	\label{eq:SquaredLossFunction}
	\boxed{L(\mathbf{w}; S) = \sum_{l=1}^N \left( f(\mathbf{x}^{(l)}; \mathbf{w}) - \mathbf{y}^{(l)} \right)^2 = \sum_{l=1}^N \left( w_0 + w_1 x_1^{(l)} + w_2 x_2^{(l)} + \ldots + w_d x_d^{(l)} - \mathbf{y}^{(l)} \right)^2}
	\end{equation}

	The \highlightbluetext{mean squared error} (MSE) can be defined as the average of the squared loss function across all $N$ training samples:
	\begin{equation}
	\label{eq:MeanSquaredError}
	\boxed{\text{MSE}(\mathbf{w}; S) = \frac{1}{N} L(\mathbf{w}; S) = \frac{1}{N} \sum_{l=1}^N \left( f(\mathbf{x}^{(l)}; \mathbf{w}) - \mathbf{y}^{(l)} \right)^2}
	\end{equation}

	\newpage
	The squared loss function has two scenarios: $d = 1$ and $d > 1$, with $d$ representing the count of features in the input $\mathbf{x}$.

	\subsubsection{Special Case: Single-Output Regression ($d = 1$)}
	\label{subsubsec:SingleOutputRegression}
	Considering the squared loss function for single-output regression, the loss function can be represented as:
	\begin{equation}
	\label{eq:SingleOutputRegressionLossFunction}
	\boxed{L(w_0, w_1; S) = \sum_{l=1}^N \left( w_0 + w_1 x^{(l)} - y^{(l)} \right)^2}
	\end{equation}
	The distinctive optimal solution $\mathbf{w} = \begin{bmatrix} w_0 \\ w_1 \end{bmatrix}$ can be obtained by minimizing the loss function $L(w_0, w_1; S)$ through the least squares technique. 
	
	To find the optimal solution, one can calculate the partial derivatives of the loss function concerning $w_0$ and $w_1$, equate them to zero, and resolve the resulting equations:
	\begin{align*}
	\frac{\partial L}{\partial w_0} &= 2 \sum_{l=1}^N \left( w_0 + w_1 x^{(l)} - y^{(l)} \right) \cdot 1 = 0 \implies \sum_{l=1}^N \left( w_0 + w_1 x^{(l)}\right) = \sum_{l=1}^N y^{(l)} \implies Nw_0 + w_1 \sum_{l=1}^N x^{(l)} = \sum_{l=1}^N y^{(l)} \\
	\frac{\partial L}{\partial w_1} &= 2 \sum_{l=1}^N \left( w_0 + w_1 x^{(l)} - y^{(l)} \right) x^{(l)} = 0 \implies w_0 \sum_{l=1}^N x^{(l)} + w_1 \sum_{l=1}^N x^{(l)^2} = \sum_{l=1}^N y^{(l)} x^{(l)}
	\end{align*}
	We have a system of linear equations consisting of two equations and two unknown variables, which can be represented in matrix notation as:
	\begin{equation}
	\label{eq:SingleOutputRegressionMatrixForm}
	\boxed{\mathbf{Aw} = \begin{bmatrix} N & \sum_{l=1}^N x^{(l)} \\ \sum_{l=1}^N x^{(l)} & \sum_{l=1}^N x^{(l)^2} \end{bmatrix} \begin{bmatrix} w_0 \\ w_1 \end{bmatrix} = \begin{bmatrix} \sum_{l=1}^N y^{(l)} \\ \sum_{l=1}^N y^{(l)} x^{(l)} \end{bmatrix} = \mathbf{b}}
	\end{equation}
	Assuming the matrix $\mathbf{A}$ is invertible, the optimal solution can be found by multiplying both sides of the equation by $\mathbf{A}^{-1}$:
	\begin{equation}
	\label{eq:SingleOutputRegressionOptimalSolution}
	\boxed{\mathbf{w} = \mathbf{A}^{-1} \mathbf{b}}
	\end{equation}

	\subsubsection{General Case: Multi-Output Regression ($d > 1$)}
	\label{subsubsec:MultiOutputRegression}
	In multi-output regression, two methods can be used to identify the best solution. 
	
	The initial strategy is to utilize the \highlightbluetext{least squares method}. Initially, we represent the input and output sections of the $N$ examples as:
	\begin{align*}
		\mathbf{X} = \begin{bmatrix}
			1 & x_1^{(1)} & x_2^{(1)} & \ldots & x_d^{(1)} \\
			1 & x_1^{(2)} & x_2^{(2)} & \ldots & x_d^{(2)} \\
			\vdots & \vdots & \vdots & \ddots & \vdots \\
			1 & x_1^{(N)} & x_2^{(N)} & \ldots & x_d^{(N)}
		\end{bmatrix} \in \mathbb{R}^{N \times (d + 1)} \quad \text{and} \quad
		\mathbf{Y} = \begin{bmatrix}
			y_1^{(1)} \\
			y_2^{(1)} \\
			\vdots \\
			y_d^{(N)}
		\end{bmatrix} \in \mathbb{R}^{N \times d}
	\end{align*}
	We obtain a system of $d + 1$ linear equations involving $d + 1$ unknowns, which can be represented in matrix form as:
	\begin{equation}
	\label{eq:MultiOutputRegressionMatrixForm}
	\boxed{\mathbf{Aw} = (\mathbf{X}^T \mathbf{X}) \mathbf{w} = \mathbf{X}^T \mathbf{y} = \mathbf{b}}
	\end{equation}
	Assuming the matrix $\mathbf{A} = \mathbf{X}^T \mathbf{X}$ is invertible, one can determine the optimal solution by multiplying both sides of the equation by $\mathbf{A}^{-1}$:
	\begin{equation}
	\label{eq:MultiOutputRegressionOptimalSolution}
	\boxed{\mathbf{w} = \mathbf{A}^{-1} \mathbf{b} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}}
	\end{equation}

	\newpage
	An alternative method is to differentiate using \highlightbluetext{Multivariable Calculus}. Initially, we can represent $\mathbf{Xw} - \mathbf{Y}$ as:
	\begin{align*}
		\mathbf{Xw} - \mathbf{Y} = \begin{bmatrix}
			1 & x_1^{(1)} & x_2^{(1)} & \ldots & x_d^{(1)} \\
			1 & x_1^{(2)} & x_2^{(2)} & \ldots & x_d^{(2)} \\
			\vdots & \vdots & \vdots & \ddots & \vdots \\
			1 & x_1^{(N)} & x_2^{(N)} & \ldots & x_d^{(N)} 
		\end{bmatrix} \begin{bmatrix} w_0 \\ w_1 \\ w_2 \\ \vdots \\ w_d \end{bmatrix} - \begin{bmatrix}
			y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(N)}
		\end{bmatrix} = \begin{bmatrix}
			w_0 + w_1 x_1^{(1)} + w_2 x_2^{(1)} + \ldots + w_d x_d^{(1)} - y^{(1)} \\
			w_0 + w_1 x_1^{(2)} + w_2 x_2^{(2)} + \ldots + w_d x_d^{(2)} - y^{(2)} \\
			\vdots \\
			w_0 + w_1 x_1^{(N)} + w_2 x_2^{(N)} + \ldots + w_d x_d^{(N)} - y^{(N)}
		\end{bmatrix}
	\end{align*}
	The squared loss function can be represented as the \highlightgreentext{squared L-2 norm of the vector} $\mathbf{Xw} - \mathbf{y}$:
	\begin{equation}
	\label{eq:MultiOutputRegressionSquaredLossFunction}
	\boxed{L(\mathbf{w}; S) = \left\| \mathbf{Xw} - \mathbf{y} \right\|^2}
	\end{equation}
	Then we can express the squared loss function as:
	\begin{align*}
		L(\mathbf{w}; S) = \left( \mathbf{Xw} - \mathbf{y} \right)^T \left( \mathbf{Xw} - \mathbf{y} \right) = \mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w} - 2 \mathbf{y}^T \mathbf{X} \mathbf{w} + \mathbf{y}^T \mathbf{y}
	\end{align*}
	To reduce the squared loss function, we can calculate the gradient of $L(\mathbf{w}; S)$ concerning $\mathbf{w}$ and equate it to zero:
	\begin{align*}
		\nabla_{\mathbf{w}} L(\mathbf{w}; S) = 2 \mathbf{X}^T \mathbf{X} \mathbf{w} - 2 \mathbf{X}^T \mathbf{y} = 0
		&\implies \mathbf{X}^T \mathbf{X} \mathbf{w} = \mathbf{X}^T \mathbf{y} \\
		&\implies \mathbf{w} = \left( \mathbf{X}^T \mathbf{X} \right)^{-1} \mathbf{X}^T \mathbf{y}
	\end{align*}

	To find the optimal solution $\mathbf{w}$, we must compute the inverse of the matrix $\mathbf{X}^T \mathbf{X} \in \mathbb{R}^{(d + 1) \times (d + 1)}$. We can apply the \highlightbluetext{LeGall algorithm}, recognized as the quickest identified method for matrix multiplication, exhibiting a \highlightgreentext{time complexity of $O(n^{2.3728596})$} for an $n \times n$ matrix, in contrast to the straightforward $O(n^3)$ approach used in Cholesky decomposition, LU decomposition, or Gaussian elimination.

	\subsection{Nonlinear Extension of Linear Regression}
	\label{subsec:NonlinearExtensionOfLinearRegression}
	Nonlinear regression functions are crucial because more complex issues cannot be addressed by linear regression. To tackle this, we can modify the linear regression function $f(\mathbf{x}; \mathbf{w})$ into a nonlinear format by adding nonlinear transformations of the input features. Three distinct methods exist for nonlinear expansions to accomplish this:
	\begin{enumerate}
		\item \highlightbluetext{Feature Engineering}: Intentionally generate additional input dimensions (nonlinearly related to the original input) and utilize linear regression on the newly created input dimensions. For instance, if the original input is $\mathbf{x} = (x_1, x_2)$, we can generate additional features like $x_1^2$, $x_2^2$, and $x_1 x_2$ to create an updated input $\mathbf{\tilde{x}} = (1, x_1, x_2, x_1^2, x_2^2, x_1 x_2)$. 

		The key benefit is that linear regression remains applicable, and the weights in the model are \highlightgreentext{highly interpretable} (the greater the weight's magnitude, the more significant the feature). The primary drawback is that it necessitates domain expertise to develop new features and can be costly in terms of computation if the feature count is high.
		\begin{center}
			\scalebox{0.8}{
			\begin{tikzpicture}
				\node at (0, 0) {$x_1$};
				\node at (0, -0.4) {$\vdots$};
				\node at (0, -0.9) {$x_d$};
				\node at (0, -2.1) {$x_{d +1}$};
				\node at (0, -2.5) {$\vdots$};
				\node at (0, -3.0) {$x_{d + n}$};
				\draw[->] (0.5, 0) -- (1.7, 0);
				\draw[->] (0.5, -0.9) -- (1.7, -0.9);
				\draw[->] (0.5, -2.1) -- (1.7, -2.1);
				\draw[->] (0.5, -3.0) -- (1.7, -3.0);

				\draw (1.7, 0.25) rectangle (3.7, -3.25);
				\node at (2.7, -1.2) {Linear};
				\node at (2.7, -1.5) {Regression};
				\node at (2.7, -1.8) {Function};

				\draw[->] (3.7, -1.5) -- (4.5, -1.5);
			\end{tikzpicture}}
		\end{center}

		\newpage
		\item \highlightbluetext{Explicit Mapping}: Apply an explicitly defined \highlightgreentext{nonlinear regression function} $f(\mathbf{x}; \mathbf{w})$ that is nonlinear in the input $\mathbf{x}$, such as polynomial regression, radial basis function (RBF) regression, or neural networks. The model learns the parameters $\mathbf{w}$ of the nonlinear function directly from the training data.
		
		\begin{center}
			\scalebox{0.8}{
			\begin{tikzpicture}
				\node at (0, 0) {$x_1$};
				\node at (0, -0.4) {$\vdots$};
				\node at (0, -0.9) {$x_d$};
				\draw[->] (0.5, 0) -- (1.7, 0);
				\draw[->] (0.5, -0.9) -- (1.7, -0.9);

				\draw (1.7, 0.25) rectangle (3.7, -1.15);
				\node at (2.7, -0.15) {Nonlinear};
				\node at (2.7, -0.45) {Regression};
				\node at (2.7, -0.75) {Function};

				\draw[->] (3.7, -0.6) -- (4.5, -0.6);
			\end{tikzpicture}}
		\end{center}

		\item \highlightbluetext{Implicit Mapping}: Implement an \highlightgreentext{implicitly defined nonlinear transformation} on the original input, followed by utilizing a linear regression function on the modified input. This method employs kernel techniques or neural networks with latent layers to automatically acquire valuable feature representations without their explicit specification. For instance, kernel techniques such as Support Vector Machines (SVM) implicitly transform the input into a higher-dimensional space via kernel functions.

		\begin{center}
			\scalebox{0.8}{
			\begin{tikzpicture}
				\node at (0, 0) {$x_1$};
				\node at (0, -0.4) {$\vdots$};
				\node at (0, -0.9) {$x_d$};
				\draw[->] (0.5, 0) -- (1.6, 0);
				\draw[->] (0.5, -0.9) -- (1.6, -0.9);

				\draw (1.6, 0.25) rectangle (3.3, -1.15);
				\node at (2.45, -1.45) {$k >> d$};
				\node at (2.45, -0.15) {Implicit};
				\node at (2.45, -0.45) {Nonlinear};
				\node at (2.45, -0.75) {Transform};

				\draw[->] (3.3, 0) -- (4.0, 0) node [midway, above] {$z_1$};
				\node at (3.65, -0.4) {$\vdots$};
				\draw[->] (3.3, -0.9) -- (4.0, -0.9) node [midway, below] {$z_k$};

				\draw (4.0, 0.25) rectangle (5.7, -1.15);
				\node at (4.85, -0.15) {Linear};
				\node at (4.85, -0.45) {Regression};
				\node at (4.85, -0.75) {Function};

				\draw[->] (5.7, -0.6) -- (6.6, -0.6);
			\end{tikzpicture}}
		\end{center}
	\end{enumerate}

	\subsection{Polynomial Regression}
	\label{subsec:PolynomialRegression}
	Polynomial Regression introduces higher-order polynomial terms as the additional input features in the linear regression function. The polynomial regression function can be expressed as:
	\begin{equation}
		\boxed{f(\mathbf{x}; \mathbf{w}) = w_0 + w_1 x + \ldots + w_m x^m = \begin{bmatrix} w_0 & w_1 & \ldots & w_m \end{bmatrix} \begin{bmatrix} 1 \\ x \\ \vdots \\ x^m \end{bmatrix} = \mathbf{w}^T \mathbf{\tilde{x}} = \mathbf{\tilde{x}}^T \mathbf{w}}
	\end{equation}
	\begin{itemize}
		\item The parameter vector $\mathbf{w} = (w_0, w_1, \ldots, w_m)$ consists of $m + 1$ parameters, where $m$ is the degree of the polynomial. 
		\item The input $\mathbf{\tilde{x}} = (1, x, x^2, \ldots, x^m)$ represents the polynomial features derived from the original input $x$.
	\end{itemize}
	Although $f(\mathbf{x}; \mathbf{w})$ is nonlinear with respect to the input $x$, it stays linear concerning the parameters $\mathbf{w}$. Consequently, we can utilize the same least squares technique to determine the ideal parameter vector $\mathbf{w}$ by minimizing the squared loss function.

	Additionally, we can employ \highlightgreentext{broader transformations} of the initial input dimensions to develop polynomial features. For example, feature engineering can specify the features tailored to the application that are used on the input data, including interaction terms or transformations specific to the domain. Using body weight and body height as an illustration, the body mass index (BMI) will be the supplementary characteristic specified. The least squares method for linear regression remains applicable to determine the optimal parameter vector $\mathbf{w}$ for acquiring the \highlightgreentext{closed form solution}.

	\subsection{Regularization}
	\label{subsec:Regularization}
	Regularization is a technique that alters the original loss function by incorporating one or more penalty terms known as \highlightbluetext{regularizers} that discourage large parameter values to avoid overfitting due to excessively high parameter magnitudes.

	\newpage

	\highlightbluetext{Overfitting} arises when the \highlightgreentext{training dataset $S = \{(\mathbf{x}^{(l)}, \mathbf{y}^{(l)})\}_{l=1}^N$ is limited in size relative to the number of parameters in the linear regression model $f(\mathbf{x}; \mathbf{w})$}. In this scenario, the model could discover significant values in certain parameters, as an expanded search space enables the model to align more closely with the training data, which may result in inadequate generalization on new data.

	Regularization helps tackle this issue by constraining the magnitude of the parameters, promoting simpler models that are less likely to overfit the training data. The \highlightbluetext{loss function with regularization} employing \highlightbluetext{$L_2$ regularization / Tikhonov regularization} can be represented as:
	\begin{equation}
	\label{eq:RegularizedLossFunction}
	\boxed{L_{\lambda}(\mathbf{w}; S) = L(\mathbf{w}; S) + \lambda \|\mathbf{w}\|^2 = \|\mathbf{Xw} - \mathbf{y}\|^2 + \lambda \|\mathbf{w}\|^2 = \mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w} - 2 \mathbf{y}^T \mathbf{X} \mathbf{w} + \mathbf{y}^T \mathbf{y} + \lambda \mathbf{w}^T \mathbf{w}}
	\end{equation}
	\begin{itemize}
		\item The parameter $\lambda > 0$ serves as a \highlightbluetext{regularization hyperparameter} that regulates the intensity of the regularization, established during the validation phase. \\
		A greater $\lambda$ produces more intense regularization, whereas a lesser $\lambda$ causes weaker regularization.
		\item The notation $\|\mathbf{w}\|^2$ signifies the squared L2 norm of the parameter vector $\mathbf{w}$, imposing a penalty on large parameter values.
	\end{itemize}
	In practice, the bias $w_0$ is frequently left out of the regularization term since it merely acts as an \highlightgreentext{offset} and does not add to the model's complexity. The loss function with regularization can be optimized through techniques like gradient descent or by utilizing \highlightgreentext{closed-form solutions}.

	To find the closed-form solution with $L_2$ regularization, we can differentiate the loss function $L_{\lambda}(\mathbf{w}; S)$ with respect to $\mathbf{w}$ and set it to zero:
	\begin{align*}
		2 \mathbf{X}^T \mathbf{X} \mathbf{w} - 2 \mathbf{X}^T \mathbf{y} + 2 \lambda \mathbf{w} = 0 \implies (\mathbf{X}^T \mathbf{X} + \lambda \mathbf{I}) \mathbf{w} = \mathbf{X}^T \mathbf{y} \quad \text{where } \mathbf{I} \text{ is the identity matrix}
	\end{align*}
	The closed-form solution for the least squares estimate of the parameter vector $\mathbf{w}$ with $L_2$ regularization can be defined as:
	\begin{equation}
	\label{eq:RegularizedClosedFormSolution}
	\boxed{\mathbf{w} = (\mathbf{X}^T \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^T \mathbf{y}} \quad \text{where } \mathbf{X}^T \mathbf{X} + \lambda \mathbf{I} \text{ is invertible for } \lambda > 0
	\end{equation}
	This regularized method is referred to as \highlightbluetext{Ridge Regression}. It minimizes overfitting and enhances the model's ability to generalize to new data by imposing penalties on large parameter values. Crucially, when the regularization parameter $\lambda$ is equal to zero, ridge Regression reduces to standard linear regression, since no penalty is enforced.

	\subsubsection{Choice of Regularization Parameter $\lambda$}
	\label{subsubsec:ChoiceOfRegularizationParameter}
	The regularization coefficient $\lambda$ is an essential hyperparameter that dictates the intensity of the regularization imposed on the model. The selection of $\lambda$ can greatly influence the performance of the model and is usually established via a validation process. A frequent method for determining the best value of $\lambda$ is to employ \highlightbluetext{cross-validation}.

	Cross-validation involves \highlightgreentext{splitting the training dataset into multiple subsets (folds) and training the model on one subset} while evaluating it on the remaining data. Subsequently, the trained model is \highlightgreentext{evaluated on a separate validation set} to resemble the test set. The procedure is carried out for different $\lambda$ values, and the model's effectiveness is assessed utilizing a specific metric (e.g., mean squared error, accuracy). The best performance on the validation set is achieved by choosing the optimal regularization parameter as the value of $\lambda$ with the smallest validation error.

	\newpage
	The standard training and validation error curves for various $\lambda$ values are illustrated below. 
	\begin{center}
		\begin{tikzpicture}[scale= 0.05]
			\draw [-latex](0, 0) -- (100, 0) node[right]{$\lambda$};
			\draw [-latex](0, 0) -- (0, 50) node[left]{Error Rate};
			\node (0, 0) at (-5, 0) {0};
			% Halved y-coordinates for both curves
			\draw [red] plot [smooth, tension=0.5] coordinates {(2, 35) (20, 27.5) (30, 22.5) (40, 15) (60, 25) (80, 30) (90, 35)} node[right]{Validation};
			\draw [blue] plot [smooth, tension=1] coordinates { (2, 1) (20, 5) (40, 10) (60, 12.5) (80, 19) (90, 27.5)} node[right]{Training};
		\end{tikzpicture}
	\end{center}
	The training error usually rises with an increase in $\lambda$, whereas the validation error first drops and then rises, suggesting that \highlightgreentext{a low $\lambda$ causes overfitting whereas a high $\lambda$ leads to underfitting}.

	\subsubsection{Other Regularization Techniques}
	\label{subsubsec:OtherRegularizationTechniques}
	In addition to $L_2$ regularization, other approaches can also be used to prevent overfitting in machine learning models. A general framework for these methods is provided by the $L_p$ norm, which generalizes both the $L_1$ and $L_2$ norms. By varying the value of $p$, a family of regularization strategies can be defined:
	\begin{equation}
		\boxed{\|\mathbf{v}\|_p = \left( \sum_{i=1}^{n} |v_i|^p \right)^{1/p} \quad \text{for } p \geq 1}
	\end{equation}
	Among these, \highlightbluetext{$L_1$ regularization}, known as \highlightbluetext{LASSO (Least Absolute Shrinkage and Selection Operator)}, is especially popular. LASSO adds a penalty term based on the $L_1$ norm of the parameter vector $\mathbf{w}$ to the loss function, which encourages sparsity by driving many coefficients to exactly zero:
	\begin{equation}
	\label{eq:LassoLossFunction}
		\boxed{L_{\lambda}(\mathbf{w}; S) = L(\mathbf{w}; S) + \lambda \|\mathbf{w}\|_1 = \|\mathbf{Xw} - \mathbf{y}\|^2 + \lambda \sum_{i=0}^{d} |w_i|}
	\end{equation}
	While $L_1$ regularization leads to a convex optimization problem, it does not admit a closed-form solution. Instead, iterative optimization algorithms such as coordinate descent or subgradient descent are typically used to find the optimal parameter vector $\mathbf{w}$.

	\subsection{Common Performance Metrics for Linear Regression}
	\label{subsec:CommonPerformanceMetricsForLinearRegression}
	To evaluate the performance of linear regression models, several metrics are commonly used. These metrics help assess how well the model predicts the target variable and can guide improvements in model design. Two of the most widely used metrics are \highlightbluetext{Mean Squared Error (MSE)} and \highlightbluetext{R-squared Scores}.

	\subsubsection{Mean Squared Error (MSE)}
	\label{subsubsec:MeanSquaredError}
	Once a regression model has been trained, it is crucial to quantitatively evaluate how accurately the model's predictions align with the real target values. A commonly utilized metric for this aim is the \highlightbluetext{Mean Squared Error (MSE)}. MSE computes the \highlightgreentext{mean of the squared deviations between the predicted values and the actual target values for all samples}. It is described as:
	\begin{equation}
	\label{eq:MeanSquaredErrorDefinition}
		\boxed{\text{MSE} = \frac{1}{N} \sum_{l = 1}^{N} \left( f(\mathbf{x}^{(l)}; \mathbf{w}) - \mathbf{y}^{(l)} \right)^2 = \frac{1}{N} L(\mathbf{w}; S)}
	\end{equation}
	\begin{itemize}
		\item $N$ is the total number of samples in the dataset, $f(\mathbf{x}^{(l)}; \mathbf{w})$ is the predicted value for the $l$-th sample, and $\mathbf{y}^{(l)}$ is the corresponding true value.
	\end{itemize}
	MSE can be calculated on the training set, validation set, or test set to assess model performance and generalization.

	Nonetheless, since MSE is represented in the squared units of the target variable, interpreting it directly can be challenging. To tackle this, the \highlightbluetext{Root Mean Squared Error (RMSE)} is commonly employed, as it calculates the square root of the MSE to revert the error to the initial scale of the target variable:
	\begin{equation}
	\label{eq:RootMeanSquaredErrorDefinition}
		\boxed{\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{N} \sum_{l = 1}^{N} \left( f(\mathbf{x}^{(l)}; \mathbf{w}) - \mathbf{y}^{(l)} \right)^2}}
	\end{equation}
	Consequently, RMSE is easier to understand and gives a clear indication of the usual size of prediction errors in the same units as the target variable.

	\subsubsection{R-squared ($R^2$) Score}
	\label{subsubsec:RSquaredScore}
	Though MSE and RMSE offer an absolute assessment of prediction error, having a relative metric that shows how effectively the model accounts for the variability in the target variable against a basic baseline is often beneficial. The \highlightbluetext{R-squared ($R^2$) value}, often referred to as the \highlightbluetext{coefficient of determination}, fulfills this role.

	$R^2$ measures the fraction of the overall variability in the target variable that the model's predictions explain. It is characterized as:
	\begin{equation}
	\label{eq:RSquaredScoreDefinition}
		\boxed{R^2 = 1 - \frac{\sum_{l = 1}^{N} \left( f(\mathbf{x}^{(l)}; \mathbf{w}) - \mathbf{y}^{(l)} \right)^2}{\sum_{l = 1}^{N} \left( \mathbf{y}^{(l)} - \bar{\mathbf{y}} \right)^2} = 1 - \frac{\text{MSE}}{\text{VAR}(\mathbf{y})}} \quad \text{where } \bar{\mathbf{y}} = \frac{1}{N} \sum_{l = 1}^{N} \mathbf{y}^{(l)} \text{ is the mean of the target variable}
	\end{equation}
	\begin{itemize}
		\item The numerator is the residual sum of squares (RSS), indicating the variance that remains unexplained (the discrepancy between predicted and actual values).
		\item The denominator is the total sum of squares (TSS), which indicates the overall variance in the target variable concerning its average.
	\end{itemize}
	$R^2$ varies between 0 and 1, with \highlightgreentext{1 indicating that the model completely accounts for all variability} in the target variable, and \highlightgreentext{0 signifying no explanation} at all (similar to predicting the average consistently). Negative $R^2$ values may arise when the model is less effective than merely predicting the average, signifying inadequate model fit.

	\newpage
	\section{Logistic Regression}
	\label{sec:LogisticRegression}

	\subsection{What is Logistic Regression?}
	\label{subsec:WhatIsLogisticRegression}
	\definition{Logistic Regression is a statistical method used for \highlightbluetext{classification} tasks. Unlike linear regression, which predicts continuous values, logistic regression maps linear combinations of input features to probabilities of class membership using the logistic function (sigmoid function) for binary classification and the softmax function for multiclass classification.}
	
	Logistic regression addresses the fundamental difference between regression and classification problems. While linear regression outputs continuous values that can range from negative infinity to positive infinity, classification requires outputs that represent probabilities (bounded between 0 and 1) or discrete class assignments.

	The key distinction between linear regression and logistic regression lies in their transformation functions:
	\begin{itemize}
		\item \highlightbluetext{Linear Regression}: Uses the identity function to directly output continuous values for regression problems.
		\item \highlightbluetext{Logistic Regression}: Uses transformation functions to convert linear combinations into probability distributions for classification problems:
		\begin{itemize}
			\item \highlightgreentext{Logistic function (sigmoid)} for binary classification
			\item \highlightgreentext{Softmax function} for multiclass classification
		\end{itemize}
	\end{itemize}

	\subsection{Types of Classification Problems}
	\label{subsec:TypesOfClassificationProblems}
	
	Before diving into logistic regression specifics, it is essential to understand the different types of classification problems:

	\subsubsection{Binary Classification}
	\label{subsubsec:BinaryClassification}
	Binary classification involves distinguishing between exactly two classes. The training set is represented as $S = \{(\mathbf{x}^{(l)}, y^{(l)})\}_{l=1}^N$ where $y^{(l)} \in \{0, 1\}$. Common examples include:
	\begin{itemize}
		\item Email spam detection: \{spam, not spam\}
		\item Medical diagnosis: \{disease, no disease\}
		\item Face detection: \{face, non-face\}
		\item Image classification: \{dog, cat\}
	\end{itemize}

	\subsubsection{Multiclass Classification}
	\label{subsubsec:MulticlassClassification}
	Multiclass classification involves $K \geq 3$ classes where each input belongs to exactly one class. The training set is $S = \{(\mathbf{x}^{(l)}, \mathbf{y}^{(l)})\}_{l=1}^N$ where $\mathbf{y}^{(l)} \in \{0, 1\}^K$ using \highlightbluetext{one-hot encoding}. In one-hot encoding, $y_j^{(l)} = 1$ if and only if $\mathbf{x}^{(l)} \in C_j$, and all other components are 0.

	Examples include:
	\begin{itemize}
		\item Animal classification: \{dog, cat, cow\}
		\item Digit recognition: \{0, 1, 2, ..., 9\}
		\item Email folder assignment in Outlook
	\end{itemize}

	For binary classification ($K = 2$), the second output becomes redundant since $y_2^{(l)} = 1 - y_1^{(l)}$.

	\subsubsection{Multilabel Classification}
	\label{subsubsec:MultilabelClassification}
	Multilabel classification differs from multiclass classification in that each input can belong to multiple classes simultaneously. Unlike multiclass classification where exactly one output is 1, in multilabel classification each output can independently be 0 or 1.

	\begin{center}
		\begin{tabular}{|l|l|}
			\hline
			\textbf{Multiclass} & \textbf{Multilabel} \\
			\hline
			One and only one output is 1 & Each output can be 0 or 1 \\
			Email folders (Outlook) & Email labels (Gmail) \\
			Single class assignment & Multiple tags possible \\
			\hline
		\end{tabular}
	\end{center}

	Examples of multilabel classification include email tagging systems where an email can have multiple labels like "travel" and "insurance" simultaneously. Multilabel classification can be approached as multiple independent binary classification problems.

	\newpage
	\subsection{Binary Classification with Logistic Regression}
	\label{subsec:BinaryClassificationWithLogisticRegression}

	\subsubsection{The Sigmoid Function}
	\label{subsubsec:TheSigmoidFunction}
	The foundation of binary logistic regression is the \highlightbluetext{sigmoid function} (also called the logistic function), which maps any real number to a value between 0 and 1:

	\begin{equation}
	\label{eq:SigmoidFunction}
		\boxed{\sigma(z) = \frac{1}{1 + e^{-z}} \quad \forall z \in \mathbb{R}, \sigma(z) \in (0,1)}
	\end{equation}

	The sigmoid function has several important properties:
	\begin{itemize}
		\item \highlightgreentext{S-shaped curve}: Smooth transition from 0 to 1
		\item \highlightgreentext{Differentiable}: Enables gradient-based optimization
		\item \highlightgreentext{Probabilistic interpretation}: Output can be interpreted as probability
		\item \highlightgreentext{Symmetric}: $\sigma(-z) = 1 - \sigma(z)$
	\end{itemize}

	\subsubsection{Generalized Logistic Function}
	\label{subsubsec:GeneralizedLogisticFunction}
	The sigmoid function can be generalized with a scaling parameter $a > 0$:

	\begin{equation}
	\label{eq:GeneralizedSigmoid}
		\boxed{\sigma_a(z) = \frac{1}{1 + e^{-az}} \quad (a > 0)}
	\end{equation}

	Special cases include:
	\begin{itemize}
		\item $a = 1$: Standard sigmoid $\sigma(z)$
		\item $a \to \infty$: Approaches step function
		\item $a \to 0$: Approaches constant function
	\end{itemize}

	The parameter $a$ controls the steepness of the transition, providing a smooth, differentiable approximation of the step function with "switch" behavior where the output approaches 1 when the input is large and positive.

	\subsubsection{Logistic Regression Model}
	\label{subsubsec:LogisticRegressionModel}
	The binary logistic regression model combines a linear function with the sigmoid transformation:

	\begin{equation}
	\label{eq:LogisticRegressionModel}
		\boxed{f(\mathbf{x}; \mathbf{w}) = \sigma(\mathbf{w}^T \tilde{\mathbf{x}}) = \frac{1}{1 + e^{-\mathbf{w}^T \tilde{\mathbf{x}}}}}
	\end{equation}

	where $\tilde{\mathbf{x}} = [1, x_1, x_2, \ldots, x_d]^T$ includes the bias term, and $\mathbf{w} = [w_0, w_1, w_2, \ldots, w_d]^T$ are the model parameters.

	This model serves as the foundation for feedforward neural networks and can be visualized as a simple network with input nodes, weighted connections, and a sigmoid activation function.

	\subsubsection{Probabilistic Interpretation}
	\label{subsubsec:ProbabilisticInterpretation}
	The logistic regression model provides a probabilistic framework for classification:

	\begin{equation}
	\label{eq:ClassProbabilities}
		\boxed{P(y = 1 | \mathbf{x}) = f(\mathbf{x}; \mathbf{w}) = \sigma(\mathbf{w}^T \tilde{\mathbf{x}})}
	\end{equation}

	Consequently, $P(y = 0 | \mathbf{x}) = 1 - f(\mathbf{x}; \mathbf{w})$.

	The optimization goal is to adjust the parameters $\mathbf{w}$ such that:
	\begin{itemize}
		\item For $\mathbf{x}^{(l)} \in C_1$ (where $y^{(l)} = 1$): Make $f(\mathbf{x}^{(l)}; \mathbf{w}) \to 1$
		\item For $\mathbf{x}^{(l)} \in C_0$ (where $y^{(l)} = 0$): Make $f(\mathbf{x}^{(l)}; \mathbf{w}) \to 0$
	\end{itemize}

	This probabilistic interpretation assumes that the output $y$ follows a \highlightbluetext{Bernoulli distribution} parameterized by the logistic regression output.

	\subsection{Loss Function and Optimization}
	\label{subsec:LossFunctionAndOptimization}

	\subsubsection{Maximum Likelihood Estimation}
	\label{subsubsec:MaximumLikelihoodEstimation}
	Given the probabilistic interpretation, we can derive the likelihood function for the training dataset. For a single example, the probability is:

	\begin{equation}
		P(y^{(l)} | \mathbf{x}^{(l)}) = f(\mathbf{x}^{(l)}; \mathbf{w})^{y^{(l)}} (1 - f(\mathbf{x}^{(l)}; \mathbf{w}))^{1-y^{(l)}}
	\end{equation}

	For the entire dataset, assuming independence, the likelihood is:

	\begin{equation}
	\label{eq:Likelihood}
		\boxed{\mathcal{L}(\mathbf{w}) = \prod_{l=1}^{N} f(\mathbf{x}^{(l)}; \mathbf{w})^{y^{(l)}} (1 - f(\mathbf{x}^{(l)}; \mathbf{w}))^{1-y^{(l)}}}
	\end{equation}

	\subsubsection{Cross-Entropy Loss Function}
	\label{subsubsec:CrossEntropyLossFunction}
	To facilitate optimization, we work with the negative log-likelihood, which gives us the \highlightbluetext{cross-entropy loss function}:

	\begin{equation}
	\label{eq:CrossEntropyLoss}
		\boxed{L(\mathbf{w}; S) = -\log \mathcal{L}(\mathbf{w}) = -\sum_{l=1}^{N} \left[ y^{(l)} \log f(\mathbf{x}^{(l)}; \mathbf{w}) + (1 - y^{(l)}) \log(1 - f(\mathbf{x}^{(l)}; \mathbf{w})) \right]}
	\end{equation}

	The advantages of using the log-likelihood include:
	\begin{itemize}
		\item \highlightgreentext{Numerical stability}: Avoids numerical issues with very small probabilities
		\item \highlightgreentext{Convexity}: The cross-entropy loss is convex in the parameters
		\item \highlightgreentext{Computational efficiency}: Easier to differentiate and optimize
	\end{itemize}

	\remarks{The cross-entropy loss function is convex, meaning it has no local minima (though the global minimum may not be unique). This is a significant advantage over non-convex loss functions as it guarantees that gradient-based optimization methods will converge to a global optimum.}

	\subsubsection{Gradient Descent Optimization}
	\label{subsubsec:GradientDescentOptimization}
	Since the cross-entropy loss has no closed-form solution, we must use iterative optimization algorithms. \highlightbluetext{Gradient descent} is the most commonly used approach:

	\begin{equation}
	\label{eq:GradientDescentUpdate}
		\boxed{\mathbf{w}^{[t+1]} = \mathbf{w}^{[t]} - \eta \nabla_{\mathbf{w}} L(\mathbf{w}^{[t]}; S)}
	\end{equation}

	where $\eta$ is the \highlightbluetext{learning rate} and $\nabla_{\mathbf{w}} L(\mathbf{w}^{[t]}; S)$ is the gradient of the loss function.

	Each iteration of gradient descent involves two steps:
	\begin{enumerate}
		\item \textbf{Compute gradient}: Calculate $\nabla_{\mathbf{w}} L(\mathbf{w}^{[t]}; S)$
		\item \textbf{Update weights}: Move in the direction opposite to the gradient
	\end{enumerate}

	\subsubsection{Derivative of the Sigmoid Function}
	\label{subsubsec:DerivativeOfSigmoidFunction}
	A key computational advantage of the sigmoid function is that its derivative can be expressed in terms of the function itself:

	\derivation{
		Starting with $\sigma(z) = \frac{1}{1 + e^{-z}}$, we can compute:
		\begin{align}
			\sigma'(z) &= \frac{d}{dz} \left( \frac{1}{1 + e^{-z}} \right) \\
			&= \frac{0 \cdot (1 + e^{-z}) - 1 \cdot (-e^{-z})}{(1 + e^{-z})^2} \\
			&= \frac{e^{-z}}{(1 + e^{-z})^2} \\
			&= \frac{1}{1 + e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \\
			&= \sigma(z) \cdot (1 - \sigma(z))
		\end{align}
	}

	\begin{equation}
	\label{eq:SigmoidDerivative}
		\boxed{\sigma'(z) = \sigma(z)(1 - \sigma(z))}
	\end{equation}

	This property is crucial for efficient gradient computation in neural networks and allows us to compute the derivative using only the function output.

	\subsubsection{Gradient Computation}
	\label{subsubsec:GradientComputation}
	To compute the gradient of the cross-entropy loss, we need the partial derivatives with respect to each weight $w_i$:

	\derivation{
		For the logistic regression model $f(\mathbf{x}; \mathbf{w}) = \sigma(\mathbf{w}^T \tilde{\mathbf{x}})$:
		\begin{align}
			\frac{\partial f}{\partial w_i} &= \frac{\partial \sigma(\mathbf{w}^T \tilde{\mathbf{x}})}{\partial w_i} \\
			&= \sigma'(\mathbf{w}^T \tilde{\mathbf{x}}) \cdot \frac{\partial (\mathbf{w}^T \tilde{\mathbf{x}})}{\partial w_i} \\
			&= \sigma(\mathbf{w}^T \tilde{\mathbf{x}})(1 - \sigma(\mathbf{w}^T \tilde{\mathbf{x}})) \cdot x_i \\
			&= f(\mathbf{x}; \mathbf{w})(1 - f(\mathbf{x}; \mathbf{w})) x_i
		\end{align}
	}

	The gradient of the cross-entropy loss with respect to $w_i$ is:

	\begin{equation}
	\label{eq:CrossEntropyGradient}
		\boxed{\frac{\partial L}{\partial w_i} = -\sum_{l=1}^{N} \left( y^{(l)} - f(\mathbf{x}^{(l)}; \mathbf{w}) \right) x_i^{(l)} = -\sum_{l=1}^{N} \delta^{(l)} x_i^{(l)}}
	\end{equation}

	where $\delta^{(l)} = y^{(l)} - f(\mathbf{x}^{(l)}; \mathbf{w})$ represents the prediction error for the $l$-th example.

	\subsubsection{Weight Update Rule}
	\label{subsubsec:WeightUpdateRule}
	The batch gradient descent update rule for logistic regression becomes:

	\begin{equation}
	\label{eq:WeightUpdate}
		\boxed{\Delta w_i = \eta \sum_{l=1}^{N} \left( y^{(l)} - f(\mathbf{x}^{(l)}; \mathbf{w}) \right) x_i^{(l)}}
	\end{equation}

	In vector form:

	\begin{equation}
	\label{eq:VectorWeightUpdate}
		\boxed{\Delta \mathbf{w} = \eta \sum_{l=1}^{N} \left( y^{(l)} - f(\mathbf{x}^{(l)}; \mathbf{w}) \right) \tilde{\mathbf{x}}^{(l)}}
	\end{equation}

	The interpretation is intuitive: the weight change is proportional to the input magnitude times the prediction error, summed over all training examples. Larger errors and larger input values lead to larger weight updates.

	\newpage
	\subsection{Multiclass Classification with Softmax}
	\label{subsec:MulticlassClassificationWithSoftmax}

	\subsubsection{Extension to Multiple Classes}
	\label{subsubsec:ExtensionToMultipleClasses}
	For multiclass classification with $K \geq 3$ classes, we extend the binary logistic regression approach using the \highlightbluetext{softmax function}. The model now requires a weight matrix $\mathbf{W} \in \mathbb{R}^{K \times (d+1)}$ where each row $\mathbf{w}_k$ corresponds to class $C_k$.

	\subsubsection{The Softmax Function}
	\label{subsubsec:TheSoftmaxFunction}
	The softmax function generalizes the sigmoid function to multiple classes:

	\begin{equation}
	\label{eq:SoftmaxFunction}
		\boxed{\text{softmax}(\mathbf{z})_j = r_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} \in (0,1)}
	\end{equation}

	where $\mathbf{z} = [z_1, z_2, \ldots, z_K]^T$ are the linear combinations for each class.

	Key properties of the softmax function include:
	\begin{itemize}
		\item \highlightgreentext{Probability distribution}: $\sum_{j=1}^K r_j = 1$
		\item \highlightgreentext{"Rich gets richer"}: Amplifies the largest inputs while suppressing smaller ones
		\item \highlightgreentext{Differentiable}: Provides a smooth alternative to the argmax function
		\item \highlightgreentext{Generalization}: Reduces to sigmoid for $K = 2$
	\end{itemize}

	\subsubsection{Multiclass Logistic Regression Model}
	\label{subsubsec:MulticlassLogisticRegressionModel}
	The multiclass logistic regression model is defined as:

	\begin{equation}
	\label{eq:MulticlassModel}
		\boxed{f(\mathbf{x}; \mathbf{W}) = \text{softmax}(\mathbf{W} \tilde{\mathbf{x}}) = \mathbf{r}}
	\end{equation}

	where $\mathbf{r} = [r_1, r_2, \ldots, r_K]^T$ represents the probability distribution over the $K$ classes.

	The optimization goal is to adjust the weight matrix $\mathbf{W}$ such that:
	\begin{itemize}
		\item For $\mathbf{x}^{(l)} \in C_k$: Make $r_k^{(l)} \to 1$
		\item For all $j \neq k$: Make $r_j^{(l)} \to 0$
	\end{itemize}

	\subsubsection{Softmax Derivative}
	\label{subsubsec:SoftmaxDerivative}
	The derivative of the softmax function has an elegant form:

	\begin{equation}
	\label{eq:SoftmaxDerivative}
		\boxed{\frac{\partial r_j}{\partial z_k} = r_j (\delta_{jk} - r_k)}
	\end{equation}

	where $\delta_{jk}$ is the Kronecker delta ($\delta_{jk} = 1$ if $j = k$, and $0$ otherwise).

	\subsubsection{Multiclass Cross-Entropy Loss}
	\label{subsubsec:MulticlassCrossEntropyLoss}
	The likelihood for multiclass classification is:

	\begin{equation}
	\label{eq:MulticlassLikelihood}
		\boxed{\mathcal{L}(\mathbf{W}) = \prod_{l=1}^{N} \prod_{j=1}^{K} (r_j^{(l)})^{y_j^{(l)}}}
	\end{equation}

	The corresponding cross-entropy loss function is:

	\begin{equation}
	\label{eq:MulticlassCrossEntropyLoss}
		\boxed{L(\mathbf{W}; S) = -\sum_{l=1}^{N} \sum_{j=1}^{K} y_j^{(l)} \log r_j^{(l)}}
	\end{equation}

	This loss function maintains the convex property but requires iterative optimization as no closed-form solution exists.

	\subsubsection{Multiclass Gradient Computation}
	\label{subsubsec:MulticlassGradientComputation}
	The gradient of the multiclass cross-entropy loss with respect to weight $w_{ki}$ is:

	\begin{equation}
	\label{eq:MulticlassGradient}
		\boxed{\frac{\partial L}{\partial w_{ki}} = -\sum_{l=1}^{N} (y_k^{(l)} - r_k^{(l)}) x_i^{(l)}}
	\end{equation}

	The batch update rule becomes:

	\begin{equation}
	\label{eq:MulticlassWeightUpdate}
		\boxed{\Delta w_{ki} = \eta \sum_{l=1}^{N} (y_k^{(l)} - r_k^{(l)}) x_i^{(l)}}
	\end{equation}

	In vector form for each class $k$:

	\begin{equation}
	\label{eq:MulticlassVectorUpdate}
		\boxed{\Delta \mathbf{w}_k = \eta \sum_{l=1}^{N} (y_k^{(l)} - r_k^{(l)}) \tilde{\mathbf{x}}^{(l)}}
	\end{equation}

	\subsection{Regularization in Logistic Regression}
	\label{subsec:RegularizationInLogisticRegression}

	Similar to linear regression, logistic regression can benefit from regularization to prevent overfitting, especially when the number of features is large relative to the number of training examples.

	\subsubsection{$L_2$ Regularization}
	\label{subsubsec:L2RegularizationLogistic}
	For binary logistic regression, $L_2$ regularization adds a penalty term to the cross-entropy loss:

	\begin{equation}
	\label{eq:RegularizedLogisticLoss}
		\boxed{L_{\text{reg}}(\mathbf{w}; S) = L(\mathbf{w}; S) + \lambda \|\mathbf{w}\|^2}
	\end{equation}

	For multiclass logistic regression, we use the Frobenius norm of the weight matrix:

	\begin{equation}
	\label{eq:RegularizedMulticlassLoss}
		\boxed{L_{\text{reg}}(\mathbf{W}; S) = L(\mathbf{W}; S) + \lambda \|\mathbf{W}\|_F^2}
	\end{equation}

	where $\|\mathbf{W}\|_F^2 = \sum_{k=1}^K \sum_{i=1}^{d+1} w_{ki}^2$ is the Frobenius norm.

	Practical considerations for regularization include:
	\begin{itemize}
		\item $\lambda > 0$: Regularization strength parameter
		\item Typically exclude bias terms from regularization
		\item Prevents overfitting by controlling model complexity
		\item Requires tuning via cross-validation
	\end{itemize}

	\newpage
	\subsection{Performance Metrics for Classification}
	\label{subsec:PerformanceMetricsForClassification}

	Evaluating classification models requires different metrics than regression. While accuracy is the most intuitive metric, it can be misleading for imbalanced datasets or when different types of errors have different costs.

	\subsubsection{Confusion Matrix}
	\label{subsubsec:ConfusionMatrix}
	The \highlightbluetext{confusion matrix} provides a comprehensive view of classification performance for binary classification:

	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			& \textbf{Predicted Positive} & \textbf{Predicted Negative} \\
			\hline
			\textbf{Actual Positive} & True Positive (TP) & False Negative (FN) \\
			\hline
			\textbf{Actual Negative} & False Positive (FP) & True Negative (TN) \\
			\hline
		\end{tabular}
	\end{center}

	From the confusion matrix, we can derive several important metrics:

	\begin{equation}
	\label{eq:Accuracy}
		\boxed{\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}}
	\end{equation}

	\subsubsection{Precision, Recall, and F1 Score}
	\label{subsubsec:PrecisionRecallF1}
	
	\textbf{Precision} measures the exactness of positive predictions:
	\begin{equation}
	\label{eq:Precision}
		\boxed{P = \frac{\text{TP}}{\text{TP} + \text{FP}}}
	\end{equation}

	\textbf{Recall} (also called sensitivity) measures the completeness of positive predictions:
	\begin{equation}
	\label{eq:Recall}
		\boxed{R = \frac{\text{TP}}{\text{TP} + \text{FN}}}
	\end{equation}

	\textbf{F1 Score} provides a balanced measure by computing the harmonic mean of precision and recall:
	\begin{equation}
	\label{eq:F1Score}
		\boxed{F1 = 2 \cdot \frac{P \cdot R}{P + R} = \frac{2\text{TP}}{2\text{TP} + \text{FP} + \text{FN}}}
	\end{equation}

	The F1 score is particularly useful for imbalanced datasets where accuracy can be misleading.

	\example{
		Consider a binary classification problem with the following confusion matrix:
		\begin{itemize}
			\item TP = 5, TN = 90, FP = 0, FN = 5
			\item Total examples = 100
		\end{itemize}

		Computing the metrics:
		\begin{align}
			\text{Accuracy} &= \frac{95}{100} = 0.95 \\
			\text{Precision} &= \frac{5}{5} = 1.0 \\
			\text{Recall} &= \frac{5}{10} = 0.5 \\
			\text{F1} &= 2 \cdot \frac{1.0 \cdot 0.5}{1.0 + 0.5} = \frac{2}{3} \approx 0.667
		\end{align}

		While the accuracy appears high at 95\%, the low recall (50\%) indicates that the model misses half of the positive cases. The F1 score of 0.667 provides a more balanced assessment of performance.
	}

	\remarks{For imbalanced datasets, accuracy can be misleading. A model that always predicts the majority class will achieve high accuracy but provide no useful information about the minority class. Precision, recall, and F1 score provide more meaningful insights into model performance across different classes.}

\end{document}